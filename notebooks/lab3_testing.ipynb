{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gunte\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "EMBED_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# RU_DATASET_PATH = \"1mcorpus/corpus.en_ru.1m.ru\"\n",
    "# EN_DATASET_PATH = \"1mcorpus/corpus.en_ru.1m.en\"\n",
    "\n",
    "# SPACY_EN = spacy.load('en_core_web_sm')\n",
    "# SPACY_RU = spacy.load('ru_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение на cpu\n"
     ]
    }
   ],
   "source": [
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = 'cpu'\n",
    "print(\"Обучение на {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(tokenized_en, tokenized_ru):\n",
    "    for en_sentence, ru_sentence in zip(tokenized_en, tokenized_ru):\n",
    "        yield en_sentence, ru_sentence\n",
    "\n",
    "def build_vocab(tokenized_text):\n",
    "    def yield_tokens(data_iter):\n",
    "        for sentence in data_iter:\n",
    "            yield sentence[0]\n",
    "    return build_vocab_from_iterator(yield_tokens(tokenized_text), specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
    "\n",
    "def text_pipeline(text, vocab):\n",
    "    return [vocab[\"<sos>\"]] + [vocab[token] for token in text] + [vocab[\"<eos>\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/en_tokenized', 'rb') as f:\n",
    "    en_tokenized_imported = pickle.load(f)\n",
    "\n",
    "with open('../data/rus_tokenized', 'rb') as f:\n",
    "    rus_tokenized_imported = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_en = build_vocab(en_tokenized_imported)\n",
    "vocab_ru = build_vocab(rus_tokenized_imported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    en_batch, ru_batch = [], []\n",
    "    for en_item, ru_item in batch:\n",
    "        en_batch.append(torch.tensor(text_pipeline(en_item[0], vocab_en), dtype=torch.long))\n",
    "        ru_batch.append(torch.tensor(text_pipeline(ru_item[0], vocab_ru), dtype=torch.long))\n",
    "\n",
    "    en_batch = pad_sequence(en_batch, padding_value=vocab_en[\"<pad>\"])\n",
    "    ru_batch = pad_sequence(ru_batch, padding_value=vocab_ru[\"<pad>\"])\n",
    "\n",
    "    return en_batch, ru_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, en_sentences, ru_sentences):\n",
    "        self.en_sentences = en_sentences\n",
    "        self.ru_sentences = ru_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.en_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.en_sentences[idx], self.ru_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(en_tokenized_imported, rus_tokenized_imported)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(test_dataset,\n",
    "                              batch_size=1,\n",
    "                              collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
      "        [   72,    95,   209,  ...,    47,  3072,   164],\n",
      "        [   71, 68802,    28,  ...,     4,    13,    14],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]])\n",
      "tensor([[     2,      2,      2,  ...,      2,      2,      2],\n",
      "        [344695,   3404,    214,  ...,     22,  14022,    858],\n",
      "        [  3564,   1196,   1397,  ...,    127,   1613,   1095],\n",
      "        ...,\n",
      "        [     1,      1,      1,  ...,      1,      1,      1],\n",
      "        [     1,      1,      1,  ...,      1,      1,      1],\n",
      "        [     1,      1,      1,  ...,      1,      1,      1]])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_dataloader))\n",
    "print(sample[0], sample[1], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input: [batch_size]\n",
    "        input = input.unsqueeze(0)  # [1, batch_size]\n",
    "        embedded = self.dropout(self.embedding(input))  # [1, batch_size, emb_dim]\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        # output: [1, batch_size, hidden_dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder, pad_idx):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        # Тензор для хранения предсказанных токенов\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        hidden = self.encoder(src)\n",
    "\n",
    "        input = trg[0, :]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        output = self(src, trg)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss(ignore_index=self.pad_idx)(output, trg)\n",
    "        self.log('train_loss', loss, batch_size=BATCH_SIZE)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        output = self(src, trg, 0) \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss(ignore_index=self.pad_idx)(output, trg)\n",
    "        self.log('val_loss', loss, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=len(vocab_en),\n",
    "                  emb_dim=EMBED_DIM,\n",
    "                  hidden_dim=HIDDEN_DIM,\n",
    "                  n_layers=N_LAYERS,\n",
    "                  dropout=DROPOUT)\n",
    "\n",
    "decoder = Decoder(output_dim=len(vocab_ru),\n",
    "                  emb_dim=EMBED_DIM,\n",
    "                  hidden_dim=HIDDEN_DIM,\n",
    "                  n_layers=N_LAYERS,\n",
    "                  dropout=DROPOUT\n",
    "                 )\n",
    "\n",
    "TRG_PAD_IDX = 1\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(381308, 256)\n",
       "    (rnn): GRU(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(766133, 256)\n",
       "    (rnn): GRU(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=766133, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual training loop\n",
    "num_epochs = 25\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        src, trg = batch  # Ensure DataLoader returns (src, trg)\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)  # Pass both src and trg to forward\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Optional: Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            src, trg = batch\n",
    "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)  # Disable teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)(output, trg)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(valid_dataloader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(model, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'seq2seq_model_10_epochs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca371fe0f64415c8b6b0303dabeb758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     6.580455303192139     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    6.580455303192139    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 6.580455303192139}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.validate(model, valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"seq2seq_model_10_epochs.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перевод: Почему вы хотите ? ? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def translate_sentence(sentence, vocab_en, vocab_ru, model, max_len=50):\n",
    "    model.eval()\n",
    "    \n",
    "    # Токенизация и числовое представление исходного предложения\n",
    "    tokens = tokenizer_en(sentence) \n",
    "    numericalized = [vocab_en[\"<sos>\"]] + [vocab_en[token] for token in tokens] + [vocab_en[\"<eos>\"]]\n",
    "    src_tensor = torch.tensor(numericalized, dtype=torch.long).unsqueeze(1).to(model.device)  # (len, 1)\n",
    "\n",
    "    hidden = model.encoder(src_tensor)\n",
    "\n",
    "    # Инициализация входного токена для декодера (токен <sos>)\n",
    "    trg_indexes = [vocab_ru[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.tensor([trg_indexes[-1]], dtype=torch.long).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        # Если предсказан токен <eos>, то прерываем цикл\n",
    "        if pred_token == vocab_ru[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    trg_tokens = [vocab_ru.get_itos()[i] for i in trg_indexes]\n",
    "\n",
    "    # Возвращаем предсказанный перевод без токенов <sos> и <eos>\n",
    "    return trg_tokens[1:-1]\n",
    "\n",
    "sentence = \"how are you\"\n",
    "translated_sentence = translate_sentence(sentence, vocab_en, vocab_ru, model)\n",
    "print(\"Перевод:\", \" \".join(translated_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
