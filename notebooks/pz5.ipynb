{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQAQDKKPfnci",
        "outputId": "cacfa8d3-bfe9-4cd2-d838-2c4c9a4ae337"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle \n",
        "\n",
        "\n",
        "filename = 'vacancies.pickle'\n",
        "with open(\"../data/better_preprocessed_TRAIN_lda_data\", 'rb') as f:\n",
        "  train = pickle.load(f)\n",
        "# train  = pd.read_csv(\"../data/better_preprocessed_TRAIN_lda_data.csv\")\n",
        "# test  = pd.read_csv(\"/data/test_processed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"../data/better_preprocessed_TEST_lda_data\", 'rb') as f:\n",
        "  test = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l_i20ufOnPcJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=20000) # не забываем про n-грамы и фиксацию размера словаря\n",
        "\n",
        "train_vectorized = vectorizer.fit_transform(train[\"text\"].values)\n",
        "test_vectorized = vectorizer.transform(test[\"text\"].values)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKLGqYpiwLcY"
      },
      "source": [
        "#LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOB-ENqJxsAP"
      },
      "source": [
        "Latent Dirichlet Allocation - Скрытое распределение Дирихле"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xrInDvhUpTAm"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda_model_sklearn = LatentDirichletAllocation(n_components=15, random_state=42)\n",
        "lda_model_sklearn.fit(train_vectorized)\n",
        "\n",
        "lda_topics_test_sklearn = lda_model_sklearn.transform(test_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc2emKbJTpFf",
        "outputId": "cf4f61cc-1231-4b53-f066-d8debd4b4790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.23916066e-04 1.23915953e-04 6.27722841e-02 ... 1.23916073e-04\n",
            "  1.23915996e-04 1.52317183e-01]\n",
            " [1.74065014e-04 2.47414673e-02 7.03254549e-01 ... 1.74064798e-04\n",
            "  1.74064802e-04 1.75465117e-01]\n",
            " [2.22965744e-04 2.22965718e-04 2.22966081e-04 ... 2.22965885e-04\n",
            "  2.22965815e-04 2.22965853e-04]\n",
            " ...\n",
            " [1.30719325e-04 1.02397323e-01 2.88630983e-01 ... 1.30719151e-04\n",
            "  1.30719349e-04 1.30719283e-04]\n",
            " [4.79972889e-02 1.02419748e-01 1.15740993e-04 ... 1.15740973e-04\n",
            "  1.15740993e-04 1.15741102e-04]\n",
            " [5.42006671e-04 7.40151716e-02 5.42007197e-04 ... 5.42006644e-04\n",
            "  5.42006472e-04 5.59199847e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(lda_topics_test_sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxE5osPV1cws",
        "outputId": "56e0cb4e-282a-44f4-f32f-ca60b17c2382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['абакумов' 'аббас' 'аббревиатура' ... 'ёлочный' 'ёмкий' 'ёмкость'] 20000\n"
          ]
        }
      ],
      "source": [
        "vocab = vectorizer.get_feature_names_out()\n",
        "print(vocab, len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLPeUGbr3AgJ",
        "outputId": "8cf2171a-3b12-4c9b-ff59-9d725ba0be75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тема 1: ['свой', 'весь', 'год', 'песня', 'новый', 'очень', 'концерт', 'стать', 'время', 'ещё']\n",
            "Тема 2: ['год', 'весь', 'свой', 'человек', 'музей', 'церковь', 'памятник', 'время', 'храм', 'наш']\n",
            "Тема 3: ['россия', 'военный', 'российский', 'год', 'украина', 'страна', 'сша', 'мочь', 'свой', 'весь']\n",
            "Тема 4: ['суд', 'дело', 'свой', 'закон', 'мочь', 'год', 'выбор', 'весь', 'депутат', 'партия']\n",
            "Тема 5: ['самолёт', 'мочь', 'год', 'весь', 'наш', 'ещё', 'продукт', 'время', 'полёт', 'человек']\n",
            "Тема 6: ['вода', 'человек', 'весь', 'год', 'животное', 'день', 'собака', 'мочь', 'ещё', 'время']\n",
            "Тема 7: ['человек', 'фильм', 'очень', 'весь', 'свой', 'театр', 'год', 'мочь', 'жизнь', 'говорить']\n",
            "Тема 8: ['весь', 'свой', 'год', 'ребёнок', 'человек', 'мочь', 'говорить', 'знать', 'ещё', 'сказать']\n",
            "Тема 9: ['человек', 'врач', 'ребёнок', 'год', 'мочь', 'весь', 'медицинский', 'пациент', 'помощь', 'лечение']\n",
            "Тема 10: ['год', 'москва', 'дом', 'весь', 'город', 'новый', 'рубль', 'строительство', 'квартира', 'район']\n",
            "Тема 11: ['человек', 'сотрудник', 'дело', 'год', 'машина', 'весь', 'полиция', 'свой', 'место', 'стать']\n",
            "Тема 12: ['школа', 'ребёнок', 'год', 'весь', 'москва', 'работа', 'московский', 'область', 'образование', 'человек']\n",
            "Тема 13: ['год', 'рубль', 'россия', 'страна', 'российский', 'цена', 'весь', 'мочь', 'экономика', 'деньга']\n",
            "Тема 14: ['команда', 'игра', 'сборная', 'чемпионат', 'матч', 'год', 'мир', 'весь', 'россия', 'первый']\n",
            "Тема 15: ['свой', 'россия', 'человек', 'страна', 'весь', 'год', 'власть', 'наш', 'мочь', 'президент']\n"
          ]
        }
      ],
      "source": [
        "# .components_ - количество раз, когда слово было назначено теме\n",
        "\n",
        "for idx, topic in enumerate(lda_model_sklearn.components_):\n",
        "    # .argsort() индексы, которые отсортируют массив topic по возрастанию\n",
        "    # [:-top_words_count - 1:-1] - необходимо взять последние индексы из отсортированного массива\n",
        "    top_words = [vocab[i] for i in topic.argsort()[: -11:-1]]\n",
        "    print(f\"Тема {idx+1}: {top_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ava9W7uDVS2V",
        "outputId": "d30bae35-4b19-456b-941e-295e115513b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Документ 1 - Тема:4\n",
            "Документ 2 - Тема:2\n",
            "Документ 3 - Тема:8\n",
            "Документ 4 - Тема:0\n",
            "Документ 5 - Тема:3\n",
            "Документ 6 - Тема:7\n",
            "Документ 7 - Тема:11\n",
            "Документ 8 - Тема:3\n",
            "Документ 9 - Тема:12\n",
            "Документ 10 - Тема:4\n"
          ]
        }
      ],
      "source": [
        "doc_topic = lda_model_sklearn.transform(test_vectorized)\n",
        "\n",
        "for n in range(10):\n",
        "    topic_doc = doc_topic[n].argmax()\n",
        "    print(f\"Документ {n+1} - Тема:{topic_doc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpmxuHmGVpGm"
      },
      "source": [
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c1Tn6SiweHe",
        "outputId": "2132655f-26ba-4d82-99d1-d6cbbc986e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<gensim.matutils.Sparse2Corpus object at 0x000002526B909F10>\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'type' object is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Выводим содержимое корпуса\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# for doc in gensim_corpus_train:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     print(doc)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(gensim_corpus_train)\n\u001b[1;32m---> 10\u001b[0m id2word\u001b[38;5;241m=\u001b[39m{i: word \u001b[38;5;28;01mfor\u001b[39;00m word, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdict\u001b[39m}\n\u001b[0;32m     12\u001b[0m gensim_dictionary \u001b[38;5;241m=\u001b[39m Dictionary\u001b[38;5;241m.\u001b[39mfrom_corpus(gensim_corpus_train, id2word\u001b[38;5;241m=\u001b[39mid2word)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(gensim_dictionary)\n",
            "\u001b[1;31mTypeError\u001b[0m: 'type' object is not iterable"
          ]
        }
      ],
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.matutils import Sparse2Corpus\n",
        "\n",
        "#  documents_columns=False - строки  представляют собой документы, а столбцы — это уникальные слова\n",
        "gensim_corpus_train = Sparse2Corpus(train_vectorized, documents_columns=False) # id слова и частота\n",
        "# Выводим содержимое корпуса\n",
        "# for doc in gensim_corpus_train:\n",
        "#     print(doc)\n",
        "print(gensim_corpus_train)\n",
        "id2word={i: word for word, i in dict}\n",
        "\n",
        "gensim_dictionary = Dictionary.from_corpus(gensim_corpus_train, id2word=id2word)\n",
        "print(gensim_dictionary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUkbQHwOLYeB"
      },
      "outputs": [],
      "source": [
        "from gensim.models.ldamodel import LdaModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNdCxS3oweKG",
        "outputId": "5e176706-35ef-4436-a3e6-9aea8e18bfc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ],
      "source": [
        "lda_model_gensim = LdaModel(corpus=gensim_corpus_train, id2word=gensim_dictionary, num_topics=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CzmGB4tweMx",
        "outputId": "30e3fe70-f94f-424c-f463-02c5e8bb5955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тема 0: ['это', 'который', 'год', 'всё', 'мочь', 'свой', 'человек', 'весь', 'ещё', 'первый']\n",
            "Тема 1: ['это', 'год', 'который', 'мочь', 'свой', 'всё', 'весь', 'время', 'человек', 'говорить']\n",
            "Тема 2: ['это', 'который', 'год', 'всё', 'человек', 'свой', 'весь', 'мочь', 'время', 'ещё']\n",
            "Тема 3: ['это', 'всё', 'человек', 'свой', 'который', 'год', 'весь', 'мочь', 'время', 'ребёнок']\n",
            "Тема 4: ['год', 'это', 'всё', 'который', 'свой', 'человек', 'мочь', 'весь', 'россия', 'наш']\n",
            "Тема 5: ['это', 'год', 'который', 'человек', 'всё', 'мочь', 'весь', 'свой', 'время', 'говорить']\n",
            "Тема 6: ['это', 'который', 'год', 'всё', 'человек', 'весь', 'свой', 'россия', 'мочь', 'время']\n",
            "Тема 7: ['год', 'это', 'который', 'всё', 'весь', 'человек', 'свой', 'мочь', 'россия', 'наш']\n",
            "Тема 8: ['это', 'год', 'который', 'свой', 'всё', 'мочь', 'наш', 'время', 'россия', 'весь']\n",
            "Тема 9: ['это', 'всё', 'который', 'свой', 'мочь', 'весь', 'человек', 'год', 'россия', 'очень']\n",
            "Тема 10: ['это', 'который', 'год', 'свой', 'всё', 'человек', 'весь', 'мочь', 'россия', 'говорить']\n",
            "Тема 11: ['это', 'который', 'всё', 'свой', 'год', 'человек', 'мочь', 'россия', 'весь', 'очень']\n",
            "Тема 12: ['год', 'это', 'который', 'всё', 'весь', 'человек', 'мочь', 'свой', 'наш', 'первый']\n",
            "Тема 13: ['это', 'который', 'год', 'человек', 'мочь', 'всё', 'весь', 'свой', 'ещё', 'время']\n",
            "Тема 14: ['это', 'всё', 'весь', 'который', 'свой', 'год', 'человек', 'мочь', 'очень', 'большой']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "lda_topics_gensim = lda_model_gensim.print_topics(num_topics=15, num_words=10)\n",
        "for idx, topic in lda_topics_gensim:\n",
        "    # Используем регулярные выражения для извлечения слов\n",
        "    words = re.findall(r'\"(.*?)\"', topic)\n",
        "    print(f\"Тема {idx}: {words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl6UwIqlY8_E"
      },
      "source": [
        "# NMF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmeJzxBNZ9La"
      },
      "source": [
        "Non-Negative Matrix Factorization (NMF) - Неотрицательная матричная факторизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7nBJGLMZBGL"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nmf_model_sklearn = NMF(n_components=15, random_state=42)\n",
        "nmf_model_sklearn.fit(train_vectorized)\n",
        "\n",
        "nmf_topics_test_sklearn = lda_model_sklearn.transform(test_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkd5kohbZBJr",
        "outputId": "d5ca07a1-30e1-4210-c58c-835e2c992e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тема 1: ['это', 'человек', 'всё', 'мочь', 'который', 'говорить', 'просто', 'сказать', 'очень', 'знать']\n",
            "Тема 2: ['год', 'это', 'весь', 'который', 'первый', 'наш', 'новый', 'москва', 'тысяча', 'время']\n",
            "Тема 3: ['ребёнок', 'родитель', 'школа', 'всё', 'семья', 'свой', 'это', 'мама', 'сын', 'жить']\n",
            "Тема 4: ['свой', 'всё', 'год', 'жизнь', 'весь', 'стать', 'очень', 'ещё', 'время', 'первый']\n",
            "Тема 5: ['лотерея', 'государственный', 'проведение', 'срок', 'всероссийский', 'рубль', 'билет', 'русский', 'лото', 'бестиражный']\n",
            "Тема 6: ['который', 'это', 'страна', 'россия', 'свой', 'власть', 'президент', 'российский', 'наш', 'сша']\n",
            "Тема 7: ['который', 'это', 'памятник', 'здание', 'объект', 'всё', 'работа', 'исторический', 'наш', 'должный']\n",
            "Тема 8: ['всё', 'очередь', 'весь', 'ещё', 'мочь', 'человек', 'это', 'центр', 'наш', 'документ']\n",
            "Тема 9: ['спортсмен', 'сборная', 'это', 'слепой', 'который', 'инвалид', 'россия', 'игра', 'спорт', 'тренер']\n",
            "Тема 10: ['квартира', 'город', 'жильё', 'цена', 'год', 'москва', 'руб', 'подмосковье', 'объект', 'район']\n",
            "Тема 11: ['дело', 'суд', 'это', 'год', 'всё', 'свой', 'следователь', 'мочь', 'день', 'который']\n",
            "Тема 12: ['витамин', 'продукт', 'человек', 'также', 'организм', 'особенно', 'это', 'мг', 'углевод', 'содержаться']\n",
            "Тема 13: ['человек', 'дом', 'который', 'всё', 'свой', 'день', 'мочь', 'отец', 'алексей', 'белый']\n",
            "Тема 14: ['партия', 'россия', 'выборы', 'который', 'депутат', 'мочь', 'фракция', 'закон', 'голос', 'кандидат']\n",
            "Тема 15: ['область', 'место', 'регион', 'московский', 'это', 'работа', 'тверской', 'наш', 'человек', 'дорога']\n"
          ]
        }
      ],
      "source": [
        "for idx, topic in enumerate(nmf_model_sklearn.components_):\n",
        "    # .argsort() индексы, которые отсортируют массив topic по возрастанию\n",
        "    # [:-top_words_count - 1:-1] - необходимо взять последние индексы из отсортированного массива\n",
        "    top_words = [vocab[i] for i in topic.argsort()[: -11:-1]]\n",
        "    print(f\"Тема {idx+1}: {top_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzhWwkJwZBPM"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Nmf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urpuMQTPZuU-"
      },
      "outputs": [],
      "source": [
        "Nmf_model_gensim = Nmf(corpus=gensim_corpus_train, id2word=gensim_dictionary, num_topics=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cazAqqWeaIM-",
        "outputId": "3865adc6-1da8-4f31-888c-3e69268b65c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тема 0: ['свой', 'год', 'это', 'песня', 'наш', 'время', 'стать', 'фильм', 'российский', 'случай']\n",
            "Тема 1: ['который', 'мочь', 'свой', 'россия', 'российский', 'наш', 'никто', 'партия', 'театр', 'вопрос']\n",
            "Тема 2: ['это', 'всё', 'ребёнок', 'человек', 'мочь', 'свой', 'очень', 'просто', 'школа', 'родитель']\n",
            "Тема 3: ['свой', 'год', 'ребёнок', 'дело', 'всё', 'дом', 'страна', 'семья', 'сын', 'весь']\n",
            "Тема 4: ['дело', 'говорить', 'день', 'ещё', 'сказать', 'время', 'мочь', 'первый', 'наталья', 'всё']\n",
            "Тема 5: ['россия', 'который', 'москва', 'новый', 'мочь', 'год', 'власть', 'это', 'партия', 'место']\n",
            "Тема 6: ['это', 'который', 'год', 'область', 'человек', 'очень', 'наш', 'работа', 'всё', 'должный']\n",
            "Тема 7: ['год', 'это', 'весь', 'всё', 'свой', 'очень', 'человек', 'первый', 'ещё', 'говорить']\n",
            "Тема 8: ['лотерея', 'год', 'государственный', 'рубль', 'срок', 'страна', 'весь', 'проведение', 'партия', 'число']\n",
            "Тема 9: ['который', 'это', 'квартира', 'год', 'говорить', 'человек', 'весь', 'город', 'жильё', 'баня']\n",
            "Тема 10: ['это', 'мочь', 'всё', 'который', 'весь', 'россия', 'человек', 'время', 'день', 'витамин']\n",
            "Тема 11: ['человек', 'область', 'район', 'наш', 'война', 'день', 'лошадь', 'дом', 'витамин', 'группа']\n",
            "Тема 12: ['который', 'это', 'памятник', 'здание', 'свой', 'наш', 'говорить', 'дом', 'исторический', 'объект']\n",
            "Тема 13: ['это', 'который', 'всё', 'ребёнок', 'страна', 'мочь', 'год', 'россия', 'новый', 'большой']\n",
            "Тема 14: ['человек', 'всё', 'дом', 'мочь', 'жизнь', 'ещё', 'стать', 'москва', 'очередь', 'работать']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "nmf_topics_gensim = Nmf_model_gensim.print_topics(num_topics=15, num_words=10)\n",
        "for idx, topic in nmf_topics_gensim:\n",
        "    # Используем регулярные выражения для извлечения слов\n",
        "    words = re.findall(r'\"(.*?)\"', topic)\n",
        "    print(f\"Тема {idx}: {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKDGwgGxaIPs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC3E0zr9a2xe"
      },
      "source": [
        "# SVD / LSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waM3cInpaISk",
        "outputId": "e104f414-1d47-479e-b891-c2ca0fffc934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тема 1: это, всё, свой, который, год\n",
            "Тема 2: это, человек, который, россия, год\n",
            "Тема 3: партия, год, новый, политический, организация\n",
            "Тема 4: ребёнок, деньга, квартира, рязанов, семья\n",
            "Тема 5: рязанов, квартира, договор, владимирович, людмила\n",
            "Тема 6: партия, человек, рязанов, деньга, ребёнок\n",
            "Тема 7: вера, русский, холодный, украина, говорить\n",
            "Тема 8: животное, россия, страна, свой, президент\n",
            "Тема 9: животное, вера, холодный, дикий, русский\n",
            "Тема 10: это, украина, ребёнок, весь, палатка\n",
            "Тема 11: деньга, год, человек, очень, украина\n",
            "Тема 12: животное, это, подпись, казахстан, школа\n",
            "Тема 13: подпись, киностудия, крым, фильм, всё\n",
            "Тема 14: украина, свой, любовь, город, москва\n",
            "Тема 15: подпись, кандидат, сбор, украина, встреча\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "lsa_model = TruncatedSVD(n_components=15)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(test_vectorized)\n",
        "lsa_components = lsa_model.components_\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(lsa_components):\n",
        "    print(f\"Тема {topic_idx + 1}: \", end='')\n",
        "    print(\", \".join([feature_names[i] for i in topic.argsort()[-5:][::-1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBoeoi89bIq2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
